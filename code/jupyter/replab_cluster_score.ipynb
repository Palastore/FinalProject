{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python2\n",
    "# -*- coding: utf-8 -*-\n",
    "import pprint\n",
    "import pymongo\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from scipy import spatial\n",
    "from scipy.sparse import isspmatrix, dok_matrix, csc_matrix\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import pylab\n",
    "\n",
    "import os\n",
    "\n",
    "import progressbar\n",
    "\n",
    "db_name = 'twitter'\n",
    "col_name = 'after_process_replab'\n",
    "\n",
    "col_output = 'cluster_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN, AffinityPropagation, MeanShift, estimate_bandwidth\n",
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "\n",
    "from igraph import *\n",
    "import igraph\n",
    "import math\n",
    "from operator import itemgetter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPrettyPrinter(pprint.PrettyPrinter):\n",
    "    def format(self, object, context, maxlevels, level):\n",
    "        if isinstance(object, unicode):\n",
    "            return (object.encode('thai'), True, False)\n",
    "        return pprint.PrettyPrinter.format(self, object, context, maxlevels, level)\n",
    "\n",
    "def go_print( input ):\n",
    "    MyPrettyPrinter().pprint(input)\n",
    "    # ppp = pprint.PrettyPrinter(indent=4)\n",
    "    # ppp.pprint(input)\n",
    "    return;\n",
    "\n",
    "def get_midnight(time):\n",
    "    return time.replace(minute=0, hour=0, second=0, microsecond=0)\n",
    "\n",
    "def get_time_gap(time,hour_gap=1,min_gap=1):\n",
    "    h = time.hour\n",
    "    m = time.minute\n",
    "    o_h = h/hour_gap*hour_gap\n",
    "    o_m = m/min_gap*min_gap\n",
    "    return time.replace(hour=o_h, minute=o_m, second=0, microsecond=0)\n",
    "\n",
    "def get_week_year(time):\n",
    "    return tuple([time.isocalendar()[0], time.isocalendar()[1]])\n",
    "\n",
    "def get_thai_midnight(time):\n",
    "    out = time + datetime.timedelta(hours=7)\n",
    "    out = out.replace(minute=0, hour=0, second=0, microsecond=0) - datetime.timedelta(hours=7)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(doc_a,doc_b):\n",
    "    return 1 - spatial.distance.cosine(doc_a, doc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "a = [1, 1, 0, 0 ,0, 2]\n",
    "b = [0, 0, 1, 2, 0, 0]\n",
    "print cosine_similarity([a], [b])\n",
    "print get_sim(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[########################################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    client = MongoClient()\n",
    "    db = client[db_name]\n",
    "\n",
    "    result = db[col_name].create_index([('ts', pymongo.ASCENDING)])\n",
    "    cursor = db[col_name].find({}).sort([('ts', pymongo.ASCENDING)])\n",
    "    \n",
    "\n",
    "    date = []\n",
    "    text = []\n",
    "    all_doc = []\n",
    "\n",
    "    bar = progressbar.ProgressBar(maxval=cursor.count()+1, widgets=[progressbar.Bar('#', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    data=1\n",
    "    for doc in cursor:\n",
    "        data += 1\n",
    "        bar.update(data)\n",
    "        \n",
    "        ts = doc['ts']\n",
    "        datetime_object = datetime.datetime.fromtimestamp(ts)\n",
    "        if True:\n",
    "#         if len(doc['hashtags']) != 0:\n",
    "            buf = doc['nouns_nltk']\n",
    "            for x in doc['hashtags']:\n",
    "                if not x.lower() in buf:\n",
    "                    buf.append(x.lower())\n",
    "            all_doc.append(doc)\n",
    "            date.append(datetime_object)\n",
    "            text.append(' '.join(buf))\n",
    "    bar.finish()\n",
    "#     print len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_group(n_cluster, all_doc, doc_key, g_id):\n",
    "        group = []\n",
    "        for i in range(n_cluster):\n",
    "            group.append([])\n",
    "        \n",
    "        for i in range( len(g_id) ):\n",
    "            group[ g_id[i] ].append(all_doc[i][doc_key])\n",
    "        return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_day(date,text,all_doc):\n",
    "    s_text = {}\n",
    "    s_all_doc = {}\n",
    "    for datetime_object in date:\n",
    "        i = date.index(datetime_object)\n",
    "        key = get_midnight(datetime_object)\n",
    "        if not s_text.has_key(key):\n",
    "            s_text[key] = []\n",
    "            s_all_doc[key] = []\n",
    "        s_text[key].append(text[i])\n",
    "        s_all_doc[key].append(all_doc[i])\n",
    "    return s_text,s_all_doc\n",
    "\n",
    "def split_week(date,text,all_doc):\n",
    "    s_text = {}\n",
    "    s_all_doc = {}\n",
    "    for datetime_object in date:\n",
    "        i = date.index(datetime_object)\n",
    "        key = get_week_year(datetime_object)\n",
    "        if not s_text.has_key(key):\n",
    "            s_text[key] = []\n",
    "            s_all_doc[key] = []\n",
    "        s_text[key].append(text[i])\n",
    "        s_all_doc[key].append(all_doc[i])\n",
    "    return s_text,s_all_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_text,s_all_doc = split_day(date,text,all_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2011, 11, 29, 0, 0), datetime.datetime(2011, 7, 18, 0, 0), datetime.datetime(2012, 6, 5, 0, 0), datetime.datetime(2012, 10, 8, 0, 0), datetime.datetime(2009, 8, 4, 0, 0), datetime.datetime(2012, 5, 28, 0, 0), datetime.datetime(2012, 9, 25, 0, 0), datetime.datetime(2012, 8, 26, 0, 0), datetime.datetime(2012, 11, 24, 0, 0), datetime.datetime(2012, 10, 10, 0, 0), datetime.datetime(2012, 6, 9, 0, 0), datetime.datetime(2011, 8, 20, 0, 0), datetime.datetime(2011, 12, 19, 0, 0), datetime.datetime(2011, 9, 15, 0, 0), datetime.datetime(2011, 1, 27, 0, 0), datetime.datetime(2011, 8, 24, 0, 0), datetime.datetime(2012, 5, 8, 0, 0), datetime.datetime(2012, 9, 13, 0, 0), datetime.datetime(2012, 7, 31, 0, 0), datetime.datetime(2012, 8, 22, 0, 0), datetime.datetime(2012, 11, 4, 0, 0), datetime.datetime(2012, 10, 27, 0, 0), datetime.datetime(2012, 5, 4, 0, 0), datetime.datetime(2011, 9, 27, 0, 0), datetime.datetime(2012, 12, 12, 0, 0), datetime.datetime(2012, 7, 3, 0, 0), datetime.datetime(2012, 2, 23, 0, 0), datetime.datetime(2011, 7, 5, 0, 0), datetime.datetime(2011, 6, 30, 0, 0), datetime.datetime(2011, 9, 23, 0, 0), datetime.datetime(2012, 12, 16, 0, 0), datetime.datetime(2012, 4, 15, 0, 0), datetime.datetime(2012, 8, 2, 0, 0), datetime.datetime(2011, 7, 9, 0, 0), datetime.datetime(2011, 11, 20, 0, 0), datetime.datetime(2012, 6, 28, 0, 0), datetime.datetime(2012, 10, 7, 0, 0), datetime.datetime(2012, 9, 30, 0, 0), datetime.datetime(2012, 4, 3, 0, 0), datetime.datetime(2012, 11, 17, 0, 0), datetime.datetime(2012, 1, 18, 0, 0), datetime.datetime(2011, 8, 13, 0, 0), datetime.datetime(2011, 7, 29, 0, 0), datetime.datetime(2011, 1, 18, 0, 0), datetime.datetime(2011, 8, 17, 0, 0), datetime.datetime(2012, 9, 2, 0, 0), datetime.datetime(2012, 8, 17, 0, 0), datetime.datetime(2012, 7, 16, 0, 0), datetime.datetime(2012, 11, 29, 0, 0), datetime.datetime(2012, 10, 18, 0, 0), datetime.datetime(2012, 5, 13, 0, 0), datetime.datetime(2010, 1, 6, 0, 0), datetime.datetime(2011, 9, 2, 0, 0), datetime.datetime(2009, 11, 21, 0, 0), datetime.datetime(2012, 12, 11, 0, 0), datetime.datetime(2011, 9, 30, 0, 0), datetime.datetime(2011, 10, 28, 0, 0), datetime.datetime(2012, 7, 4, 0, 0), datetime.datetime(2012, 11, 9, 0, 0), datetime.datetime(2012, 8, 13, 0, 0), datetime.datetime(2012, 6, 19, 0, 0), datetime.datetime(2012, 10, 30, 0, 0), datetime.datetime(2012, 9, 23, 0, 0), datetime.datetime(2012, 4, 10, 0, 0), datetime.datetime(2012, 7, 8, 0, 0), datetime.datetime(2012, 3, 10, 0, 0), datetime.datetime(2011, 11, 19, 0, 0), datetime.datetime(2012, 12, 31, 0, 0), datetime.datetime(2011, 6, 27, 0, 0), datetime.datetime(2011, 8, 2, 0, 0), datetime.datetime(2011, 7, 20, 0, 0), datetime.datetime(2012, 3, 6, 0, 0), datetime.datetime(2012, 6, 7, 0, 0), datetime.datetime(2011, 3, 2, 0, 0), datetime.datetime(2012, 5, 30, 0, 0), datetime.datetime(2012, 9, 27, 0, 0), datetime.datetime(2012, 8, 24, 0, 0), datetime.datetime(2012, 6, 11, 0, 0), datetime.datetime(2011, 8, 22, 0, 0), datetime.datetime(2012, 11, 22, 0, 0), datetime.datetime(2009, 2, 27, 0, 0), datetime.datetime(2011, 7, 24, 0, 0), datetime.datetime(2011, 9, 13, 0, 0), datetime.datetime(2011, 8, 26, 0, 0), datetime.datetime(2012, 5, 10, 0, 0), datetime.datetime(2012, 9, 15, 0, 0), datetime.datetime(2012, 12, 2, 0, 0), datetime.datetime(2012, 11, 2, 0, 0), datetime.datetime(2012, 7, 29, 0, 0), datetime.datetime(2012, 4, 25, 0, 0), datetime.datetime(2012, 8, 20, 0, 0), datetime.datetime(2012, 5, 6, 0, 0), datetime.datetime(2011, 9, 25, 0, 0), datetime.datetime(2012, 10, 21, 0, 0), datetime.datetime(2012, 11, 14, 0, 0), datetime.datetime(2012, 7, 1, 0, 0), datetime.datetime(2011, 7, 7, 0, 0), datetime.datetime(2012, 12, 22, 0, 0), datetime.datetime(2011, 6, 28, 0, 0), datetime.datetime(2011, 12, 5, 0, 0), datetime.datetime(2011, 9, 21, 0, 0), datetime.datetime(2012, 3, 15, 0, 0), datetime.datetime(2011, 7, 11, 0, 0), datetime.datetime(2011, 11, 22, 0, 0), datetime.datetime(2012, 10, 1, 0, 0), datetime.datetime(2012, 6, 30, 0, 0), datetime.datetime(2009, 6, 21, 0, 0), datetime.datetime(2012, 9, 16, 0, 0), datetime.datetime(2012, 10, 13, 0, 0), datetime.datetime(2012, 6, 2, 0, 0), datetime.datetime(2011, 8, 15, 0, 0), datetime.datetime(2012, 12, 26, 0, 0), datetime.datetime(2011, 7, 31, 0, 0), datetime.datetime(2012, 2, 12, 0, 0), datetime.datetime(2011, 8, 19, 0, 0), datetime.datetime(2012, 9, 4, 0, 0), datetime.datetime(2012, 5, 19, 0, 0), datetime.datetime(2009, 11, 7, 0, 0), datetime.datetime(2011, 6, 1, 0, 0), datetime.datetime(2012, 7, 22, 0, 0), datetime.datetime(2012, 11, 27, 0, 0), datetime.datetime(2012, 8, 31, 0, 0), datetime.datetime(2012, 9, 8, 0, 0), datetime.datetime(2012, 5, 15, 0, 0), datetime.datetime(2012, 12, 5, 0, 0), datetime.datetime(2012, 3, 23, 0, 0), datetime.datetime(2012, 7, 26, 0, 0), datetime.datetime(2012, 11, 7, 0, 0), datetime.datetime(2012, 12, 9, 0, 0), datetime.datetime(2011, 9, 28, 0, 0), datetime.datetime(2012, 8, 11, 0, 0), datetime.datetime(2011, 11, 13, 0, 0), datetime.datetime(2011, 7, 2, 0, 0), datetime.datetime(2012, 6, 21, 0, 0), datetime.datetime(2012, 10, 24, 0, 0), datetime.datetime(2011, 12, 2, 0, 0), datetime.datetime(2012, 7, 14, 0, 0), datetime.datetime(2009, 10, 9, 0, 0), datetime.datetime(2012, 8, 7, 0, 0), datetime.datetime(2011, 5, 21, 0, 0), datetime.datetime(2012, 6, 25, 0, 0), datetime.datetime(2012, 10, 4, 0, 0), datetime.datetime(2011, 12, 14, 0, 0), datetime.datetime(2011, 8, 4, 0, 0), datetime.datetime(2011, 6, 25, 0, 0), datetime.datetime(2011, 11, 25, 0, 0), datetime.datetime(2011, 7, 22, 0, 0), datetime.datetime(2012, 3, 4, 0, 0), datetime.datetime(2009, 9, 28, 0, 0), datetime.datetime(2011, 8, 8, 0, 0), datetime.datetime(2012, 5, 24, 0, 0), datetime.datetime(2012, 9, 29, 0, 0), datetime.datetime(2012, 6, 13, 0, 0), datetime.datetime(2012, 11, 20, 0, 0), datetime.datetime(2012, 9, 1, 0, 0), datetime.datetime(2011, 9, 11, 0, 0), datetime.datetime(2011, 7, 26, 0, 0), datetime.datetime(2011, 8, 28, 0, 0), datetime.datetime(2012, 7, 19, 0, 0), datetime.datetime(2012, 2, 7, 0, 0), datetime.datetime(2011, 9, 7, 0, 0), datetime.datetime(2012, 8, 18, 0, 0), datetime.datetime(2012, 10, 23, 0, 0), datetime.datetime(2012, 7, 7, 0, 0), datetime.datetime(2012, 2, 19, 0, 0), datetime.datetime(2012, 4, 19, 0, 0), datetime.datetime(2012, 8, 14, 0, 0), datetime.datetime(2012, 11, 12, 0, 0), datetime.datetime(2011, 9, 19, 0, 0), datetime.datetime(2012, 12, 20, 0, 0), datetime.datetime(2012, 6, 16, 0, 0), datetime.datetime(2011, 7, 13, 0, 0), datetime.datetime(2011, 11, 16, 0, 0), datetime.datetime(2010, 4, 16, 0, 0), datetime.datetime(2012, 10, 3, 0, 0), datetime.datetime(2012, 4, 7, 0, 0), datetime.datetime(2011, 8, 1, 0, 0), datetime.datetime(2012, 7, 11, 0, 0), datetime.datetime(2012, 9, 18, 0, 0), datetime.datetime(2009, 4, 10, 0, 0), datetime.datetime(2012, 6, 4, 0, 0), datetime.datetime(2010, 4, 12, 0, 0), datetime.datetime(2012, 10, 15, 0, 0), datetime.datetime(2012, 12, 24, 0, 0), datetime.datetime(2012, 5, 29, 0, 0), datetime.datetime(2011, 7, 17, 0, 0), datetime.datetime(2011, 11, 28, 0, 0), datetime.datetime(2013, 1, 1, 0, 0), datetime.datetime(2011, 8, 21, 0, 0), datetime.datetime(2012, 2, 14, 0, 0), datetime.datetime(2012, 9, 6, 0, 0), datetime.datetime(2011, 9, 14, 0, 0), datetime.datetime(2012, 7, 20, 0, 0), datetime.datetime(2012, 11, 25, 0, 0), datetime.datetime(2012, 6, 8, 0, 0), datetime.datetime(2012, 8, 29, 0, 0), datetime.datetime(2012, 9, 10, 0, 0), datetime.datetime(2012, 4, 26, 0, 0), datetime.datetime(2012, 7, 24, 0, 0), datetime.datetime(2012, 11, 5, 0, 0), datetime.datetime(2012, 10, 9, 0, 0), datetime.datetime(2011, 8, 25, 0, 0), datetime.datetime(2012, 12, 15, 0, 0), datetime.datetime(2011, 9, 26, 0, 0), datetime.datetime(2012, 8, 9, 0, 0), datetime.datetime(2011, 7, 4, 0, 0), datetime.datetime(2012, 6, 23, 0, 0), datetime.datetime(2012, 10, 26, 0, 0), datetime.datetime(2012, 5, 5, 0, 0), datetime.datetime(2012, 4, 14, 0, 0), datetime.datetime(2012, 7, 12, 0, 0), datetime.datetime(2012, 8, 5, 0, 0), datetime.datetime(2010, 2, 28, 0, 0), datetime.datetime(2012, 6, 27, 0, 0), datetime.datetime(2012, 10, 6, 0, 0), datetime.datetime(2011, 8, 6, 0, 0), datetime.datetime(2011, 5, 27, 0, 0), datetime.datetime(2011, 9, 22, 0, 0), datetime.datetime(2012, 3, 2, 0, 0), datetime.datetime(2011, 11, 27, 0, 0), datetime.datetime(2011, 7, 8, 0, 0), datetime.datetime(2011, 8, 10, 0, 0), datetime.datetime(2012, 5, 26, 0, 0), datetime.datetime(2012, 4, 2, 0, 0), datetime.datetime(2012, 6, 15, 0, 0), datetime.datetime(2012, 11, 18, 0, 0), datetime.datetime(2012, 5, 22, 0, 0), datetime.datetime(2012, 9, 3, 0, 0), datetime.datetime(2011, 7, 28, 0, 0), datetime.datetime(2011, 9, 9, 0, 0), datetime.datetime(2012, 3, 30, 0, 0), datetime.datetime(2012, 11, 15, 0, 0), datetime.datetime(2011, 8, 30, 0, 0), datetime.datetime(2012, 11, 30, 0, 0), datetime.datetime(2012, 7, 17, 0, 0), datetime.datetime(2011, 4, 5, 0, 0), datetime.datetime(2012, 12, 6, 0, 0), datetime.datetime(2010, 2, 17, 0, 0), datetime.datetime(2011, 9, 5, 0, 0), datetime.datetime(2012, 4, 29, 0, 0), datetime.datetime(2012, 8, 16, 0, 0), datetime.datetime(2012, 10, 17, 0, 0), datetime.datetime(2012, 11, 10, 0, 0), datetime.datetime(2012, 7, 5, 0, 0), datetime.datetime(2012, 8, 12, 0, 0), datetime.datetime(2011, 12, 1, 0, 0), datetime.datetime(2011, 9, 17, 0, 0), datetime.datetime(2010, 11, 28, 0, 0), datetime.datetime(2012, 6, 18, 0, 0), datetime.datetime(2012, 12, 10, 0, 0), datetime.datetime(2011, 10, 29, 0, 0), datetime.datetime(2011, 7, 15, 0, 0), datetime.datetime(2011, 11, 18, 0, 0), datetime.datetime(2011, 8, 3, 0, 0), datetime.datetime(2012, 9, 20, 0, 0), datetime.datetime(2012, 7, 9, 0, 0), datetime.datetime(2010, 11, 8, 0, 0), datetime.datetime(2009, 4, 8, 0, 0), datetime.datetime(2012, 6, 6, 0, 0), datetime.datetime(2012, 12, 30, 0, 0), datetime.datetime(2012, 9, 24, 0, 0), datetime.datetime(2012, 5, 31, 0, 0), datetime.datetime(2011, 7, 19, 0, 0), datetime.datetime(2011, 11, 30, 0, 0), datetime.datetime(2011, 8, 23, 0, 0), datetime.datetime(2012, 11, 23, 0, 0), datetime.datetime(2011, 10, 10, 0, 0), datetime.datetime(2011, 9, 12, 0, 0), datetime.datetime(2012, 8, 27, 0, 0), datetime.datetime(2010, 10, 5, 0, 0), datetime.datetime(2012, 6, 10, 0, 0), datetime.datetime(2012, 9, 12, 0, 0), datetime.datetime(2012, 5, 11, 0, 0), datetime.datetime(2011, 12, 18, 0, 0), datetime.datetime(2012, 7, 30, 0, 0), datetime.datetime(2011, 2, 11, 0, 0), datetime.datetime(2012, 8, 23, 0, 0), datetime.datetime(2012, 4, 24, 0, 0), datetime.datetime(2012, 2, 4, 0, 0), datetime.datetime(2011, 8, 27, 0, 0), datetime.datetime(2012, 12, 13, 0, 0), datetime.datetime(2011, 9, 24, 0, 0), datetime.datetime(2011, 3, 28, 0, 0), datetime.datetime(2011, 7, 6, 0, 0), datetime.datetime(2012, 8, 3, 0, 0), datetime.datetime(2012, 2, 16, 0, 0), datetime.datetime(2012, 7, 2, 0, 0), datetime.datetime(2011, 2, 7, 0, 0), datetime.datetime(2012, 6, 29, 0, 0), datetime.datetime(2011, 6, 29, 0, 0), datetime.datetime(2012, 12, 17, 0, 0), datetime.datetime(2011, 9, 20, 0, 0), datetime.datetime(2012, 10, 29, 0, 0), datetime.datetime(2012, 9, 17, 0, 0), datetime.datetime(2011, 11, 21, 0, 0), datetime.datetime(2011, 7, 10, 0, 0), datetime.datetime(2011, 8, 12, 0, 0), datetime.datetime(2012, 1, 21, 0, 0), datetime.datetime(2012, 11, 16, 0, 0), datetime.datetime(2012, 6, 1, 0, 0), datetime.datetime(2012, 10, 12, 0, 0), datetime.datetime(2012, 5, 16, 0, 0), datetime.datetime(2012, 9, 5, 0, 0), datetime.datetime(2011, 7, 30, 0, 0), datetime.datetime(2012, 7, 23, 0, 0), datetime.datetime(2012, 8, 30, 0, 0), datetime.datetime(2012, 11, 28, 0, 0), datetime.datetime(2011, 8, 16, 0, 0), datetime.datetime(2011, 9, 3, 0, 0), datetime.datetime(2012, 12, 4, 0, 0), datetime.datetime(2012, 11, 3, 0, 0), datetime.datetime(2012, 10, 19, 0, 0), datetime.datetime(2012, 9, 9, 0, 0), datetime.datetime(2012, 4, 23, 0, 0), datetime.datetime(2012, 8, 10, 0, 0), datetime.datetime(2012, 11, 8, 0, 0), datetime.datetime(2012, 7, 27, 0, 0), datetime.datetime(2012, 6, 20, 0, 0), datetime.datetime(2011, 12, 3, 0, 0), datetime.datetime(2012, 10, 31, 0, 0), datetime.datetime(2012, 12, 8, 0, 0), datetime.datetime(2012, 12, 7, 0, 0), datetime.datetime(2012, 3, 9, 0, 0), datetime.datetime(2011, 7, 1, 0, 0), datetime.datetime(2011, 8, 5, 0, 0), datetime.datetime(2012, 7, 15, 0, 0), datetime.datetime(2012, 9, 22, 0, 0), datetime.datetime(2012, 8, 6, 0, 0), datetime.datetime(2012, 10, 11, 0, 0), datetime.datetime(2012, 12, 28, 0, 0), datetime.datetime(2012, 6, 24, 0, 0), datetime.datetime(2012, 1, 26, 0, 0), datetime.datetime(2012, 5, 25, 0, 0), datetime.datetime(2012, 9, 26, 0, 0), datetime.datetime(2011, 7, 21, 0, 0), datetime.datetime(2011, 11, 24, 0, 0), datetime.datetime(2012, 11, 21, 0, 0), datetime.datetime(2011, 4, 12, 0, 0), datetime.datetime(2011, 8, 9, 0, 0), datetime.datetime(2010, 11, 21, 0, 0), datetime.datetime(2011, 9, 10, 0, 0), datetime.datetime(2011, 7, 25, 0, 0), datetime.datetime(2012, 6, 12, 0, 0), datetime.datetime(2012, 8, 25, 0, 0), datetime.datetime(2012, 9, 14, 0, 0), datetime.datetime(2012, 5, 21, 0, 0), datetime.datetime(2012, 7, 28, 0, 0), datetime.datetime(2012, 11, 1, 0, 0), datetime.datetime(2012, 8, 21, 0, 0), datetime.datetime(2011, 8, 29, 0, 0), datetime.datetime(2012, 2, 6, 0, 0), datetime.datetime(2012, 10, 22, 0, 0), datetime.datetime(2012, 12, 3, 0, 0), datetime.datetime(2011, 9, 6, 0, 0), datetime.datetime(2012, 8, 1, 0, 0), datetime.datetime(2012, 11, 13, 0, 0), datetime.datetime(2012, 10, 2, 0, 0), datetime.datetime(2012, 12, 23, 0, 0), datetime.datetime(2011, 9, 18, 0, 0), datetime.datetime(2011, 12, 4, 0, 0), datetime.datetime(2012, 9, 19, 0, 0), datetime.datetime(2011, 7, 12, 0, 0), datetime.datetime(2011, 11, 23, 0, 0), datetime.datetime(2011, 8, 14, 0, 0), datetime.datetime(2012, 12, 27, 0, 0), datetime.datetime(2011, 7, 16, 0, 0), datetime.datetime(2012, 6, 3, 0, 0), datetime.datetime(2012, 10, 14, 0, 0), datetime.datetime(2012, 5, 18, 0, 0), datetime.datetime(2012, 9, 7, 0, 0), datetime.datetime(2012, 11, 26, 0, 0), datetime.datetime(2012, 7, 21, 0, 0), datetime.datetime(2012, 2, 13, 0, 0), datetime.datetime(2011, 8, 18, 0, 0), datetime.datetime(2011, 9, 1, 0, 0), datetime.datetime(2012, 9, 11, 0, 0), datetime.datetime(2012, 8, 8, 0, 0), datetime.datetime(2012, 2, 25, 0, 0), datetime.datetime(2012, 11, 6, 0, 0), datetime.datetime(2012, 7, 25, 0, 0), datetime.datetime(2012, 10, 25, 0, 0), datetime.datetime(2012, 6, 22, 0, 0), datetime.datetime(2012, 12, 14, 0, 0), datetime.datetime(2011, 9, 29, 0, 0), datetime.datetime(2011, 7, 3, 0, 0), datetime.datetime(2011, 8, 7, 0, 0), datetime.datetime(2012, 12, 18, 0, 0), datetime.datetime(2012, 7, 13, 0, 0), datetime.datetime(2012, 8, 4, 0, 0), datetime.datetime(2012, 1, 28, 0, 0), datetime.datetime(2012, 10, 5, 0, 0), datetime.datetime(2012, 6, 26, 0, 0), datetime.datetime(2012, 9, 28, 0, 0), datetime.datetime(2012, 5, 27, 0, 0), datetime.datetime(2011, 7, 23, 0, 0), datetime.datetime(2011, 11, 26, 0, 0), datetime.datetime(2010, 12, 23, 0, 0), datetime.datetime(2012, 11, 19, 0, 0), datetime.datetime(2012, 12, 29, 0, 0), datetime.datetime(2011, 8, 11, 0, 0), datetime.datetime(2011, 9, 8, 0, 0), datetime.datetime(2011, 7, 27, 0, 0), datetime.datetime(2012, 6, 14, 0, 0), datetime.datetime(2012, 10, 20, 0, 0), datetime.datetime(2012, 12, 19, 0, 0), datetime.datetime(2012, 5, 23, 0, 0), datetime.datetime(2012, 8, 19, 0, 0), datetime.datetime(2011, 8, 31, 0, 0), datetime.datetime(2012, 7, 18, 0, 0), datetime.datetime(2012, 10, 16, 0, 0), datetime.datetime(2012, 12, 1, 0, 0), datetime.datetime(2011, 9, 4, 0, 0), datetime.datetime(2011, 4, 22, 0, 0), datetime.datetime(2012, 5, 3, 0, 0), datetime.datetime(2011, 11, 5, 0, 0), datetime.datetime(2011, 6, 17, 0, 0), datetime.datetime(2012, 7, 6, 0, 0), datetime.datetime(2012, 11, 11, 0, 0), datetime.datetime(2012, 8, 15, 0, 0), datetime.datetime(2012, 4, 16, 0, 0), datetime.datetime(2012, 12, 21, 0, 0), datetime.datetime(2011, 9, 16, 0, 0), datetime.datetime(2012, 6, 17, 0, 0), datetime.datetime(2012, 10, 28, 0, 0), datetime.datetime(2012, 9, 21, 0, 0), datetime.datetime(2012, 7, 10, 0, 0), datetime.datetime(2011, 11, 17, 0, 0), datetime.datetime(2011, 7, 14, 0, 0), datetime.datetime(2012, 12, 25, 0, 0), datetime.datetime(2012, 4, 4, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "print s_text.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'america', u'amp', u'appl', u'bank', u'bbva', u'berkeley', u'blog', u'broken', u'california', u'call', u'capit', u'car', u'card', u'care', u'challeng', u'concert', u'congratul', u'cut', u'day', u'director', u'emm', u'fan', u'fiat', u'ford', u'forex', u'friend', u'ft', u'fxstreetnew', u'game', u'haha', u'health', u'hollywood', u'hope', u'jennif', u'jersey', u'kid', u'kurt', u'lopez', u'marathon', u'mascot', u'matheni', u'max', u'mazda', u'mazda3', u'minut', u'news', u'night', u'note', u'panther', u'peopl', u'point', u'post', u'power', u'rb', u'regul', u'rt', u'runner', u'sale', u'season', u'shirt', u'sporti', u'stadium', u'stock', u'studi', u'subaru', u'suzuki', u'system', u'team', u'test', u'time', u'today', u'tomorrow', u'univers', u'video', u'volkswagen', u'volvo', u'vote', u'wait', u'wash', u'week', u'win', u'work', u'wow', u'yale', u'yamaha', u'yandel', u'year']\n",
      "[ 1.          0.          1.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.89442719  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.70710678  0.          0.          0.\n",
      "  0.          0.          1.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          1.          0.\n",
      "  0.5         0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.        ]\n",
      "[ 0.          1.          0.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          0.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  0.10557281  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          0.29289322  1.          1.          1.\n",
      "  1.          1.          0.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          0.          1.\n",
      "  0.5         1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "sample = []\n",
    "ts = 1349689576\n",
    "datetime_o = datetime.datetime.fromtimestamp(ts)\n",
    "k = get_midnight(datetime_o)\n",
    "\n",
    "sample = s_text[k]\n",
    "sample_doc = s_all_doc[k]\n",
    "\n",
    "# print sample\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "tf = tf_vectorizer.fit_transform(sample)\n",
    "feature_names = tf_vectorizer.get_feature_names()\n",
    "print feature_names\n",
    "# print '\\n\\n tf-idf'\n",
    "# tfidf_vectorizer_2 = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "# tf2 = tfidf_vectorizer_2.fit_transform(sample)\n",
    "# print tf2\n",
    "test = cosine_similarity(tf)\n",
    "test2 = cosine_distances(tf)\n",
    "\n",
    "# for sim in test[0]:\n",
    "#     if sim >= 0.1:\n",
    "#         print sim, test[0].tolist().index(sim)\n",
    "# print len(test)\n",
    "\n",
    "print test[0]\n",
    "print test2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 84)\t1\n",
      "[u'aaron twitcon wayn zoooom yamaha', u'wise choic power play call rb', u'yamaha sound projector deal sound projector', u'admiss today watercolor societi exhibit bank credit card #free', u'ha gustado v\\xeddeo jennif floor ft pitbul parodi awesom #37).', u'blame model hollywood stripper booti rack wow brain berkeley #novacane #frankocean', u'tiger suzuki trade haunt', u'bmw volvo deliveri fli pick car factori appl china deliveri', u'maruti suzuki wagon hatchback mileag kmpl', u'video fifa team path power liga bbva beast #6', u'ibra psg brace minut fiat', u'martin jennif wison amp yandel kovideo blog', u'bank america stadium carolina panther', u'qb rb point', u'build team year bank marathon rais fund', u'support afford duc lol', u'jennif hemlin headlin week', u'handgun area tonight gilman berkeley area gilman berkeley', u'pre pt pt studi mac dre volkswagen doe', u'bank america mafia', u'rb', u'suzuki sore tomorrow #nats #stlcards #nlds', u'call matheni ipitch count suzuki curv deep #nicejobwaino', u'congratul runner bank marathon', u'congratul runner bank marathon', u'congratul runner bank marathon', u'bank wa', u'congratul runner bank marathon', u'congratul runner bank marathon', u'congratul runner bank marathon', u'congratul runner bank marathon', u'congratul runner bank marathon', u'congratul runner bank marathon', u'wisin amp yandel leader ft jennif lopez v\\xeda', u'berkeley broken health care system note', u'bbva site', u'jennif lopez max amp emm hola jennif lopez fan keep #celebrity', u'panther game spend bank stadium', u'pronounc mark rzepczynski kurt suzuki #confused', u'jennif exampl ladi sexi', u'hope mt broken health care system note', u'rb defend gore run defend', u'friend univers translat lyric', u'auction yamaha xv virago catalogo brochur prospekt catalogu', u'driver wheel eb mazda wb lane death', u'rt player seahawk wait', u'soundtrack rnb year headi vote text pl rt win', u'bank america hartford connecticut', u'artist britney spear amp #lastfm', u'panther rush', u'rb pull win #battlewithinabattle', u'saab fact subaru', u'hollywood jennif lopez emm max sporti jersey em', u\"dinner today buddi yale daisi friend jordan #can'twait\", u'roll #500c #fiat', u'ford peopl mazda', u'yanke career jason hammel season postseason', u'jogger finish today bank marathon benefit', u'rb mathew', u'jennif lopez emm max sporti jersey', u'temperatur cloud wind humid #berkeley #california', u'kurt suzuki post season nation way game card', u'bank #troopthanks,', u'helmet2helmet rb amp head power tackl', u'mill valley film highlight berkeley director', u'beti sg point #bbva', u'mention jennif lopez el latino', u'yale nigga', u'jennif lopez guy bonu', u'cool mazda snap mazda jeep #mazda3 #mazdalove', u'jennif lopez emm max sporti jersey', u'god berkeley school tomorrow #joog', u'guess clutch thing', u'wash game matheni suzuki card', u'wait ger time coolwat #subaru #wrx #coolwater #rims', u'hope shit jennif game yesterday', u'jennif lopez emm max sporti jersey', u'yamaha xs ventur yamaha xs ventur footpegth #sale #cheap', u'googl volkswagen race car news', u'cclass lexington sale paul miller ford auto outlet', u'fiat coffe fiat test drive fiat today ipad', u'time hr bank america', u'wana haha preview day week week hope', u'jennif madrid jersey cc', u'car sale day rebat suzuki sx4 #newcarrebate', u'view #operations #jobs #rbs #careers', u'sue hope', u'yamaha yzf #wow', u'reckless practic taxpay work hand hmg steal sme', u'fxstreetnew bond pullback rb #forex', u'hear david blood boil care #macmillan #quotes #environment', u'acoust news #tdc', u'conclus berkeley studi ad industri track track approach #apc2012 #tellviceverything', u'hour yamaha leather', u'wohoo ternyata jlo itu madridista loh #halamadrid', u'deseo jennif women oz bodi wash', u'jennif lopez cut mail', u'pier pyne job kate #destroyingthejoint #qanda', u'rb abus forum safeti day today visit', u'explain men charg sex research univers', u'stock market regul consob probe carmak fiat cash report time', u'jennif lopez cut silhouett sheer #mailonline', u'jennif lopez barcelona shakira winner', u'fxstreetnew warrant term posit #forex', u'princeton economist math romney tax plan', u'fiat', u'day director help volkswagen', u'regul liquid routin check investig car maker #italy', u'institut affair univers modul foundat leadership centuri valu', u'mazda mazda3 ford lynnwood #findcars', u'yamaha rx channel network av receiv yamaha rx channel network receiv review', u'insid stock bank appl ford groupon motion companhia energetica mina', u'blog post yamaha golf buggi golf car compani rang electr #golf', u'slang kid rap geniu pleasert #world #spain #business', u'consum mini rotat strike bank america merril lynch', u'volkswagen touareg edit volkswagen edit specif pictur', u'time stori today', u'jennif lopez #soundhound', u'mom buy brother', u'berkeley california peopl day day', u'mclaren supercar subaru brz ten minut video yester', u'mascot capit mascot challeng vote', u'capit mascot challeng vote #capitalonesebastian', u'jennif lopez kid shirt night concert', u'test haha', u'hospit omg', u'jennif lopez kid shirt night concert', u'je hoort nu jennif lopez block #nowplaying #fmgoud', u'#coolasfuck #whiteteeleatherjacketandraybans', u'volvo coat lanyard polo backpack work fan', u'yale by3rfn', u'berkeley meter list today peopl day #happyipd']\n"
     ]
    }
   ],
   "source": [
    "print tf[0]\n",
    "# print feature_names[165]\n",
    "print sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "# print test[0]\n",
    "# test2 = StandardScaler().fit_transform(test)\n",
    "# print test2[0]\n",
    "print len(test2)\n",
    "# print test2[479]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid_score(tf,group_member,feature_names):\n",
    "    centroid_list = []\n",
    "    centroid_word_list = []\n",
    "    score_list = []\n",
    "    i = 0\n",
    "    for group in group_member:\n",
    "        count = np.zeros(len(feature_names))\n",
    "        for member in group:\n",
    "            count += tf[member].toarray()[0]\n",
    "        centroid = count / len(group)\n",
    "        centroid_list.append(centroid)\n",
    "        \n",
    "        centroid_word = []\n",
    "        for word_index in range(len(feature_names)):\n",
    "            if count[word_index] != 0 and centroid[word_index] > 0.5:\n",
    "                word_data = tuple([centroid[word_index] ,feature_names[word_index]])\n",
    "                centroid_word.append(word_data)\n",
    "        centroid_word_list.append( sorted(centroid_word, reverse  = True))\n",
    "        print i,':',sorted(centroid_word, reverse  = True)\n",
    "                \n",
    "        sum_sim = 0\n",
    "        for member in group:\n",
    "            m_tf = tf[member].toarray()[0]\n",
    "            sum_sim += get_sim(m_tf,centroid)\n",
    "        score = sum_sim/len(group)\n",
    "        score_list.append(score)\n",
    "        \n",
    "        i +=1\n",
    "    return centroid_list, centroid_word_list, score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dbscan(test):\n",
    "    # Compute DBSCAN\n",
    "    cluster = DBSCAN(eps=0.3, min_samples=3,metric='precomputed').fit(test)\n",
    "    # distance <= eps\n",
    "    core_samples_mask = np.zeros_like(cluster.labels_, dtype=bool)\n",
    "    core_samples_mask[cluster.core_sample_indices_] = True\n",
    "    labels = cluster.labels_\n",
    "    \n",
    "#     print cluster.core_sample_indices_\n",
    "\n",
    "    print labels\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "    if n_clusters_>1:\n",
    "        print(\"Silhouette Coefficient: %0.3f\"\n",
    "          % metrics.silhouette_score(test, labels))\n",
    "        \n",
    "    group = []\n",
    "    for i in range(n_clusters_+1):\n",
    "        group.append([])\n",
    "    index = 0\n",
    "    for i in labels:\n",
    "        group[i].append(index)\n",
    "        index += 1\n",
    "    \n",
    "    group = group[:-1]\n",
    "    # for i in range(n_clusters_):\n",
    "    #     print len(group[i])\n",
    "\n",
    "    return group, labels, n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -1  0 -1  7 -1  1 -1  1 -1  2 -1  3  4 -1 -1  7  5 -1  3  4  1 -1  6  6\n",
      "  6  3  6  6  6  6  6  6 -1 -1 -1  7  3  1  7 -1  4  8  0  9 -1 -1  3 -1 -1\n",
      "  4 -1  7 -1  2 -1 -1 -1  4  7  5 -1  3 -1  5 -1  7 -1  7  9  7  5 -1 -1 -1\n",
      " -1  7  0 -1 -1  2  3 -1  7 -1 -1 -1  0 -1 -1 -1 -1  5  0 -1  7  7 -1 -1  8\n",
      " -1  7  7 -1 -1  2 -1 -1  8  9  0 -1 -1 -1  3 -1 -1  7 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1  7 -1 -1 -1 -1]\n",
      "Estimated number of clusters: 10\n",
      "Silhouette Coefficient: 0.294\n",
      "0 [0, 2, 43, 77, 87, 93, 110]\n",
      "1 [6, 8, 21, 38]\n",
      "2 [10, 54, 80, 105]\n",
      "3 [12, 19, 26, 37, 47, 62, 81, 114]\n",
      "4 [13, 20, 41, 50, 58]\n",
      "5 [17, 60, 64, 71, 92]\n",
      "6 [23, 24, 25, 27, 28, 29, 30, 31, 32]\n",
      "7 [4, 16, 36, 39, 52, 59, 66, 68, 70, 76, 83, 95, 96, 101, 102, 117, 127]\n",
      "8 [42, 99, 108]\n",
      "9 [44, 69, 109]\n"
     ]
    }
   ],
   "source": [
    "group, labels, n_clusters_ = dbscan(test2)\n",
    "i = 0\n",
    "for mem in group:\n",
    "    print i,mem\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [u'Lyrics', u'', u'other topics', u'Spare parts - For sale', u'User comments', u'Clothing', u'']\n",
      "1 : [u'', u'Suzuki Wagon', u'', u'']\n",
      "2 : [u'fiat is small, slow', u'photos / videos', u'test drive', u'owners comments/mention on their fiat']\n",
      "3 : [u'Bofa Stadium - Panthers', u'Hate - Opinions', u'Geotag / Checking In', u'Bofa Stadium - Panthers', u'Geotag / Checking In', u'Goodwill Initiatives - Troops', u'Vacancy ', u'other topics']\n",
      "4 : [u'', u'', u'', u'', u'']\n",
      "5 : [u'', u'', u'', u'', u'UC Berkeley research']\n",
      "6 : [u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon']\n",
      "7 : [u'Fans Opinions: songs-videos', u'News about JL', u'Gossip: JL and her kids', u'Comments about her age', u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Commercials', u'Comments about JL', u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Merchandising', u'News about JL', u'News about JL', u'Comments about JL', u'Songs-Videos', u'Comments about JL']\n",
      "8 : [u\"(Student's Study) Students Translates Rap Lyrics\", u'Researchers Studies & Projects', u'Modules & Programs at Yale']\n",
      "9 : [u'Accident', u'Comparison', u'For Sale']\n"
     ]
    }
   ],
   "source": [
    "group_2 = view_group(n_clusters_+1 , sample_doc, \"topic\", labels)\n",
    "group_2 = group_2[:-1]\n",
    "x = 0\n",
    "for i in group_2:\n",
    "    print x,':',i\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [(1.25, u'yamaha')]\n",
      "1 : [(1.0, u'suzuki')]\n",
      "2 : []\n",
      "3 : [(1.0, u'rb')]\n",
      "4 : [(1.0, u'bank')]\n",
      "5 : [(1.0, u'runner'), (1.0, u'marathon'), (1.0, u'congratul'), (1.0, u'bank')]\n",
      "6 : [(1.0, u'jennif')]\n",
      "7 : [(1.0, u'sporti'), (1.0, u'max'), (1.0, u'lopez'), (1.0, u'jersey'), (1.0, u'jennif'), (1.0, u'emm')]\n",
      "8 : [(1.3333333333333333, u'mazda'), (0.66666666666666663, u'mazda3'), (0.66666666666666663, u'ford')]\n",
      "9 : [(1.0, u'lopez'), (1.0, u'jennif')]\n",
      "10 : [(1.3333333333333333, u'berkeley'), (1.0, u'day'), (0.66666666666666663, u'peopl')]\n"
     ]
    }
   ],
   "source": [
    "centroid_list, centroid_word_list, score_list = find_centroid_score(tf,group,feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AffinityPropagation\n",
    "def aff_cluster(test):\n",
    "    # Compute DBSCAN\n",
    "    cluster = AffinityPropagation(affinity='euclidean').fit(test)\n",
    "    cluster_centers_indices = cluster.cluster_centers_indices_\n",
    "    labels = cluster.labels_\n",
    "    print cluster_centers_indices\n",
    "#     print labels\n",
    "\n",
    "    # print labels\n",
    "    # Number of clusters in labels, ignoring noise if present.\n",
    "    n_clusters_ = len(set(labels))\n",
    "#     print('Estimated number of clusters: %d' % n_clusters_)\n",
    "        \n",
    "    group = []\n",
    "    for i in range(n_clusters_):\n",
    "        group.append([])\n",
    "    index = 0\n",
    "    for i in labels:\n",
    "        group[i].append(index)\n",
    "        index += 1\n",
    "        \n",
    "    regroup = []\n",
    "    relabel = []\n",
    "    index = 0\n",
    "    for mem in group:\n",
    "        if len(mem) >= 3:\n",
    "            regroup.append(mem)\n",
    "            relabel.append(index)\n",
    "#             print index\n",
    "        index += 1\n",
    "    \n",
    "    new_label = []\n",
    "    for i in labels:\n",
    "        if i in relabel:\n",
    "            new_label.append(relabel.index(i))\n",
    "        else:\n",
    "            new_label.append(-1)\n",
    "    # for i in range(n_clusters_):\n",
    "    #     print len(group[i])\n",
    "    print new_label\n",
    "    new_n_clusters_ = len(set(new_label)) - (1 if -1 in labels else 0)\n",
    "    print('Estimated number of clusters: %d' % n_clusters_)\n",
    "\n",
    "    return group, labels, n_clusters_, regroup, new_label, new_n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   6  15  20  26  30  36  39  40  61  76  80  82 109 117 121 123 131]\n",
      "[0, 3, 0, 4, 6, 2, 1, 2, 1, 2, 2, 6, 4, 3, 4, 2, 6, 10, 2, 4, 3, 1, 1, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 9, -1, 2, -1, 4, 1, 6, -1, 3, 2, 0, 2, 2, 2, 4, 2, 2, 3, 2, 7, 2, 2, 8, 2, 4, 3, 7, 2, -1, 4, 3, 2, 2, 9, 2, 9, 8, 7, 2, 2, 1, 2, 6, 7, 0, 2, 2, -1, 4, -1, 6, 1, 2, 2, 0, 2, 3, 2, 2, 2, 0, 2, 6, 9, 2, 3, 2, 2, 9, 9, 2, 2, 2, 2, 2, 2, 8, 0, 4, 0, 2, 4, 2, 2, 9, 2, 10, 2, -1, -1, -1, 2, 2, -1, 9, 2, 2, 2, 10]\n",
      "Estimated number of clusters: 12\n",
      "0 [0, 2, 43, 77, 87, 93, 110, 112]\n",
      "1 [6, 8, 21, 22, 38, 73, 84]\n",
      "2 [5, 7, 9, 10, 15, 18, 35, 42, 44, 45, 46, 48, 49, 51, 53, 54, 56, 60, 64, 65, 67, 71, 72, 74, 78, 79, 85, 86, 88, 90, 91, 92, 94, 97, 99, 100, 103, 104, 105, 106, 107, 108, 113, 115, 116, 118, 120, 124, 125, 128, 129, 130]\n",
      "3 [1, 13, 20, 41, 50, 58, 63, 89, 98]\n",
      "4 [3, 12, 14, 19, 26, 37, 47, 57, 62, 81, 111, 114]\n",
      "5 [23, 24, 25, 27, 28, 29, 30, 31, 32]\n",
      "6 [4, 11, 16, 39, 75, 83, 95]\n",
      "7 [52, 59, 70, 76]\n",
      "8 [55, 69, 109]\n",
      "9 [33, 66, 68, 96, 101, 102, 117, 127]\n",
      "10 [17, 119, 131]\n"
     ]
    }
   ],
   "source": [
    "old_group, old_labels, old_n_clusters_, group, labels, n_clusters_ = aff_cluster(tf)\n",
    "i = 0\n",
    "for mem in group:\n",
    "    print i,mem\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [u'Lyrics', u'', u'other topics', u'Spare parts - For sale', u'User comments', u'Clothing', u'', u'For sale']\n",
      "1 : [u'', u'Suzuki Wagon', u'', u'', u'', u'', u'S clients services by other companies']\n",
      "2 : [u'', u'other topics', u'Sports sponsors', u'fiat is small, slow', u'User comments', u'User Photos', u'Sports sponsors', u\"(Student's Study) Students Translates Rap Lyrics\", u'Accident', u'', u'', u'Top List', u'', u'other topics', u'Students', u'photos / videos', u'', u'', u'', u'Sports sponsors', u'', u'', u'', u'Pictures posted in social networks', u'Self-Driving Cars', u'For Sale', u'RBS Job offers', u'', u'RBS & HMG to steal from SMEs', u'', u'Conferences & Talks', u'UC Berkeley research', u'Gossip: JL and her kids', u'', u'Researchers Studies & Projects', u'fiat keeps cash on its balance sheet', u'RBS forex forecasts', u'Professors', u'owners comments/mention on their fiat', u'Check-in', u'fiat keeps cash on its balance sheet', u'Modules & Programs at Yale', u\"(Student's Study) Students Translates Rap Lyrics\", u'VW Touareg', u'', u'User Comments', u'Videos', u'', u'', u'User comments', u'praise for volvo', u'']\n",
      "3 : [u'', u'', u'', u'', u'', u'', u'', u'RBS economic analysis', u'']\n",
      "4 : [u'Bofa Credit Card', u'Bofa Stadium - Panthers', u'Bofa Chicago Marathon', u'Hate - Opinions', u'Geotag / Checking In', u'Bofa Stadium - Panthers', u'Geotag / Checking In', u'Bofa Chicago Marathon', u'Goodwill Initiatives - Troops', u'Vacancy ', u'Stock Ratings', u'other topics']\n",
      "5 : [u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon']\n",
      "6 : [u'Fans Opinions: songs-videos', u'News about JL', u'News about JL', u'Comments about her age', u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Merchandising']\n",
      "7 : [u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Gossip: JL and her kids']\n",
      "8 : [u'User Comments', u'Comparison', u'For Sale']\n",
      "9 : [u'Song-Video: Wisin Yandel ft JL Follow the leader', u'Commercials', u'Comments about JL', u'News about JL', u'News about JL', u'Comments about JL', u'Songs-Videos', u'Comments about JL']\n",
      "10 : [u'', u'', u'']\n",
      "11 : [u'', u'Gossip: JL and her kids', u'', u'', u'test drive', u'', u\"Capital One Bowl's mascot challenge\", u\"Capital One Bowl's mascot challenge\", u'Gossip: JL and her kids', u'Gossip: JL and her kids']\n"
     ]
    }
   ],
   "source": [
    "group_2 = view_group(n_clusters_ , sample_doc, \"topic\", labels)\n",
    "x = 0\n",
    "for i in group_2:\n",
    "    print x,':',i\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : ['1.25000 yamaha']\n",
      "1 : ['1.00000 suzuki']\n",
      "2 : []\n",
      "3 : ['1.00000 rb']\n",
      "4 : ['1.00000 bank']\n",
      "5 : ['1.00000 runner', '1.00000 marathon', '1.00000 congratul', '1.00000 bank']\n",
      "6 : ['1.00000 jennif']\n",
      "7 : ['1.00000 sporti', '1.00000 max', '1.00000 lopez', '1.00000 jersey', '1.00000 jennif', '1.00000 emm']\n",
      "8 : ['1.33333 mazda', '0.66667 mazda3', '0.66667 ford']\n",
      "9 : ['1.00000 lopez', '1.00000 jennif']\n",
      "10 : ['1.33333 berkeley', '1.00000 day', '0.66667 peopl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\Lib\\site-packages\\scipy\\spatial\\distance.py:505: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - np.dot(u, v) / (norm(u) * norm(v))\n"
     ]
    }
   ],
   "source": [
    "centroid_list, centroid_word_list, score_list = find_centroid_score(tf,group,feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_allclose(a, b, rtol=1e-5, atol=1e-8):\n",
    "    \"\"\"\n",
    "    Version of np.allclose for use with sparse matrices\n",
    "    \"\"\"\n",
    "    c = np.abs(a - b) - rtol * np.abs(b)\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    return c.max() <= atol\n",
    "\n",
    "\n",
    "def normalize(matrix):\n",
    "    \"\"\"\n",
    "    Normalize the columns of the given matrix\n",
    "    \n",
    "    :param matrix: The matrix to be normalized\n",
    "    :returns: The normalized matrix\n",
    "    \"\"\"\n",
    "    return sklearn.preprocessing.normalize(matrix, norm=\"l1\", axis=0)\n",
    "\n",
    "\n",
    "def inflate(matrix, power):\n",
    "    \"\"\"\n",
    "    Apply cluster inflation to the given matrix by raising\n",
    "    each element to the given power.\n",
    "    \n",
    "    :param matrix: The matrix to be inflated\n",
    "    :param power: Cluster inflation parameter\n",
    "    :returns: The inflated matrix\n",
    "    \"\"\"\n",
    "    if isspmatrix(matrix):\n",
    "        return normalize(matrix.power(power))\n",
    "\n",
    "    return normalize(np.power(matrix, power))\n",
    "\n",
    "\n",
    "def expand(matrix, power):\n",
    "    \"\"\"\n",
    "    Apply cluster expansion to the given matrix by raising\n",
    "    the matrix to the given power.\n",
    "    \n",
    "    :param matrix: The matrix to be expanded\n",
    "    :param power: Cluster expansion parameter\n",
    "    :returns: The expanded matrix\n",
    "    \"\"\"\n",
    "    if isspmatrix(matrix):\n",
    "        return matrix ** power\n",
    "\n",
    "    return np.linalg.matrix_power(matrix, power)\n",
    "\n",
    "\n",
    "def add_self_loops(matrix, loop_value):\n",
    "    \"\"\"\n",
    "    Add self-loops to the matrix by setting the diagonal\n",
    "    to loop_value\n",
    "    \n",
    "    :param matrix: The matrix to add loops to\n",
    "    :param loop_value: Value to use for self-loops\n",
    "    :returns: The matrix with self-loops\n",
    "    \"\"\"\n",
    "    shape = matrix.shape\n",
    "    assert shape[0] == shape[1], \"Error, matrix is not square\"\n",
    "\n",
    "    if isspmatrix(matrix):\n",
    "        new_matrix = matrix.todok()\n",
    "    else:\n",
    "        new_matrix = matrix.copy()\n",
    "\n",
    "    for i in range(shape[0]):\n",
    "        new_matrix[i, i] = loop_value\n",
    "\n",
    "    if isspmatrix(matrix):\n",
    "        return new_matrix.tocsc()\n",
    "\n",
    "    return new_matrix\n",
    "\n",
    "\n",
    "def prune(matrix, threshold):\n",
    "    \"\"\"\n",
    "    Prune the matrix so that very small edges are removed\n",
    "    \n",
    "    :param matrix: The matrix to be pruned\n",
    "    :param threshold: The value below which edges will be removed\n",
    "    :returns: The pruned matrix\n",
    "    \"\"\"\n",
    "    if isspmatrix(matrix):\n",
    "        pruned = dok_matrix(matrix.shape)\n",
    "        pruned[matrix >= threshold] = matrix[matrix >= threshold]\n",
    "        pruned = pruned.tocsc()\n",
    "    else:\n",
    "        pruned = matrix.copy()\n",
    "        pruned[pruned < threshold] = 0\n",
    "\n",
    "    return pruned\n",
    "\n",
    "\n",
    "def converged(matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Check for convergence by determining if \n",
    "    matrix1 and matrix2 are approximately equal.\n",
    "    \n",
    "    :param matrix1: The matrix to compare with matrix2\n",
    "    :param matrix2: The matrix to compare with matrix1\n",
    "    :returns: True if matrix1 and matrix2 approximately equal\n",
    "    \"\"\"\n",
    "    if isspmatrix(matrix1) or isspmatrix(matrix2):\n",
    "        return sparse_allclose(matrix1, matrix2)\n",
    "\n",
    "    return np.allclose(matrix1, matrix2)\n",
    "\n",
    "\n",
    "def iterate(matrix, expansion, inflation):\n",
    "    \"\"\"\n",
    "    Run a single iteration (expansion + inflation) of the mcl algorithm\n",
    "    \n",
    "    :param matrix: The matrix to perform the iteration on\n",
    "    :param expansion: Cluster expansion factor\n",
    "    :param inflation: Cluster inflation factor\n",
    "    \"\"\"\n",
    "    # Expansion\n",
    "    matrix = expand(matrix, expansion)\n",
    "\n",
    "    # Inflation\n",
    "    matrix = inflate(matrix, inflation)\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def get_clusters(matrix):\n",
    "    \"\"\"\n",
    "    Retrieve the clusters from the matrix\n",
    "    \n",
    "    :param matrix: The matrix produced by the MCL algorithm\n",
    "    :returns: A list of tuples where each tuple represents a cluster and\n",
    "              contains the indices of the nodes belonging to the cluster\n",
    "    \"\"\"\n",
    "    if not isspmatrix(matrix):\n",
    "        # cast to sparse so that we don't need to handle different \n",
    "        # matrix types\n",
    "        matrix = csc_matrix(matrix)\n",
    "\n",
    "    # get the attractors - non-zero elements of the matrix diagonal\n",
    "    attractors = matrix.diagonal().nonzero()[0]\n",
    "\n",
    "    # somewhere to put the clusters\n",
    "    clusters = set()\n",
    "\n",
    "    # the nodes in the same row as each attractor form a cluster\n",
    "    for attractor in attractors:\n",
    "        cluster = tuple(matrix.getrow(attractor).nonzero()[1].tolist())\n",
    "        clusters.add(cluster)\n",
    "\n",
    "    return sorted(list(clusters))\n",
    "\n",
    "\n",
    "def run_mcl(matrix, expansion=2, inflation=2, loop_value=1,\n",
    "            iterations=100, pruning_threshold=0.001, pruning_frequency=1,\n",
    "            convergence_check_frequency=1, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform MCL on the given similarity matrix\n",
    "    \n",
    "    :param matrix: The similarity matrix to cluster\n",
    "    :param expansion: The cluster expansion factor\n",
    "    :param inflation: The cluster inflation factor\n",
    "    :param loop_value: Initialization value for self-loops\n",
    "    :param iterations: Maximum number of iterations\n",
    "           (actual number of iterations will be less if convergence is reached)\n",
    "    :param pruning_threshold: Threshold below which matrix elements will be set\n",
    "           set to 0\n",
    "    :param pruning_frequency: Perform pruning every 'pruning_frequency'\n",
    "           iterations. \n",
    "    :param convergence_check_frequency: Perform the check for convergence\n",
    "           every convergence_check_frequency iterations\n",
    "    :param verbose: Print extra information to the console\n",
    "    :returns: The final matrix\n",
    "    \"\"\"\n",
    "    print(\"-\" * 50)\n",
    "    print(\"MCL Parameters\")\n",
    "    print(\"Expansion: {}\".format(expansion))\n",
    "    print(\"Inflation: {}\".format(inflation))\n",
    "    if pruning_threshold > 0:\n",
    "        print(\"Pruning threshold: {}, frequency: {} iteration{}\".format(\n",
    "            pruning_threshold, pruning_frequency, \"s\" if pruning_frequency > 1 else \"\"))\n",
    "    else:\n",
    "        print(\"No pruning\")\n",
    "    print(\"Convergence check: {} iteration{}\".format(\n",
    "        convergence_check_frequency, \"s\" if convergence_check_frequency > 1 else \"\"))\n",
    "    print(\"Maximum iterations: {}\".format(iterations))\n",
    "    print(\"{} matrix mode\".format(\"Sparse\" if isspmatrix(matrix) else \"Dense\"))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Initialize self-loops\n",
    "    if loop_value > 0:\n",
    "        matrix = add_self_loops(matrix, loop_value)\n",
    "\n",
    "    # Normalize\n",
    "    matrix = normalize(matrix)\n",
    "\n",
    "    # iterations\n",
    "    for i in range(iterations):\n",
    "        print(\"Iteration {}\".format(i + 1))\n",
    "\n",
    "        # store current matrix for convergence checking\n",
    "        last_mat = matrix.copy()\n",
    "\n",
    "        # perform MCL expansion and inflation\n",
    "        matrix = iterate(matrix, expansion, inflation)\n",
    "\n",
    "        # prune\n",
    "        if pruning_threshold > 0 and i % pruning_frequency == pruning_frequency - 1:\n",
    "            print(\"Pruning\")\n",
    "            matrix = prune(matrix, pruning_threshold)\n",
    "\n",
    "        # Check for convergence\n",
    "        if i % convergence_check_frequency == convergence_check_frequency - 1:\n",
    "            print(\"Checking for convergence\")\n",
    "            if converged(matrix, last_mat):\n",
    "                print(\"Converged after {} iteration{}\".format(i + 1, \"s\" if i > 0 else \"\"))\n",
    "                break\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "MCL Parameters\n",
      "Expansion: 2\n",
      "Inflation: 1.5\n",
      "Pruning threshold: 0.001, frequency: 1 iteration\n",
      "Convergence check: 1 iteration\n",
      "Maximum iterations: 100\n",
      "Dense matrix mode\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 2\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 3\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 4\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 5\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 6\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 7\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 8\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 9\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 10\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 11\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 12\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 13\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 14\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 15\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 16\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 17\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 18\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Iteration 19\n",
      "Pruning\n",
      "Checking for convergence\n",
      "Converged after 19 iterations\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mcl = run_mcl(test,inflation = 1.5)\n",
    "cluster = get_clusters(mcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_mcl(cluster, n):\n",
    "    labels = [0]*n\n",
    "    filter_labels = [0]*n\n",
    "    i = 0\n",
    "    filter_i = -1\n",
    "    num_filter = 0\n",
    "    filter_cluster = []\n",
    "    for mem in cluster:\n",
    "        if len(mem) <3:\n",
    "            num_filter = -1\n",
    "        else:\n",
    "            filter_i += 1\n",
    "            num_filter = filter_i\n",
    "            filter_cluster.append(mem)\n",
    "        for index in mem:\n",
    "            labels[index] = i\n",
    "            filter_labels[index] = num_filter\n",
    "        i += 1\n",
    "    return labels, filter_labels,filter_cluster  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,filter_labels = label_mcl(cluster, len(test))\n",
    "# print cluster\n",
    "# print labels\n",
    "# print filter_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for py 3.xx \n",
    "# import markov_clustering as mc\n",
    "\n",
    "# mcl = mc.run_mcl(test,inflation = 1.5)           # run MCL with default parameters\n",
    "# cluster = mc.get_clusters(mcl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "labels = [0]*len(test)\n",
    "g_index = 0\n",
    "for mem in cluster:\n",
    "    for i in mem:\n",
    "        labels[i] = g_index\n",
    "    g_index += 1\n",
    "n_clusters_ = len(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 2, 3, 4, 5, 6, 5, 7, 8, 3, 2, 1, 2, 9, 3, 4, 10, 2, 1, 5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 7, 3, 2, 5, 3, 4, 1, 11, 0, 12, 13, 14, 2, 3, 2, 1, 13, 3, 15, 8, 12, 16, 2, 1, 3, 4, 5, 2, 1, 4, 7, 3, 15, 3, 12, 3, 4, 17, 5, 13, 3, 3, 0, 10, 12, 8, 2, 18, 3, 5, 19, 4, 0, 6, 1, 4, 10, 4, 0, 20, 3, 3, 21, 1, 11, 8, 3, 3, 1, 22, 8, 10, 10, 11, 12, 0, 2, 0, 3, 2, 10, 8, 3, 23, 4, 13, 14, 14, 3, 18, 24, 3, 3, 25, 6, 15, 4]\n"
     ]
    }
   ],
   "source": [
    "print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [u'Lyrics', u'', u'other topics', u'Spare parts - For sale', u'User comments', u'Clothing', u'', u'For sale']\n",
      "1 : [u'', u'', u'', u'', u'', u'', u'', u'RBS economic analysis', u'', u'RBS forex forecasts']\n",
      "2 : [u'Bofa Credit Card', u'Bofa Stadium - Panthers', u'Bofa Chicago Marathon', u'Hate - Opinions', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Geotag / Checking In', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Chicago Marathon', u'Bofa Stadium - Panthers', u'Geotag / Checking In', u'', u'Bofa Chicago Marathon', u'Goodwill Initiatives - Troops', u'Vacancy ', u'Stock Ratings', u'other topics']\n",
      "3 : [u'Fans Opinions: songs-videos', u'News about JL', u'News about JL', u'Song-Video: Wisin Yandel ft JL Follow the leader', u'Gossip: JL and her kids', u'Comments about her age', u'Top List', u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Commercials', u'Comments about JL', u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Merchandising', u'News about JL', u'News about JL', u'Comments about JL', u\"(Student's Study) Students Translates Rap Lyrics\", u'Songs-Videos', u'Gossip: JL and her kids', u'Gossip: JL and her kids', u'Comments about JL']\n",
      "4 : [u'', u'', u'', u'', u'', u'', u'', u'', u'', u'UC Berkeley research', u'', u'']\n",
      "5 : [u'', u'Suzuki Wagon', u'', u'', u'', u'', u'', u'S clients services by other companies']\n",
      "6 : [u'other topics', u'RBS & HMG to steal from SMEs', u'praise for volvo']\n",
      "7 : [u'Sports sponsors', u'Sports sponsors', u'Sports sponsors']\n",
      "8 : [u'fiat is small, slow', u'photos / videos', u'test drive', u'fiat keeps cash on its balance sheet', u'owners comments/mention on their fiat', u'']\n",
      "9 : [u'User comments']\n",
      "10 : [u'User Photos', u'Self-Driving Cars', u'Conferences & Talks', u'Check-in', u'fiat keeps cash on its balance sheet', u'VW Touareg']\n",
      "11 : [u\"(Student's Study) Students Translates Rap Lyrics\", u'Researchers Studies & Projects', u'Modules & Programs at Yale']\n",
      "12 : [u'Accident', u'User Comments', u'Comparison', u'For Sale', u'For Sale']\n",
      "13 : [u'', u'other topics', u'Pictures posted in social networks', u'Videos']\n",
      "14 : [u'', u\"Capital One Bowl's mascot challenge\", u\"Capital One Bowl's mascot challenge\"]\n",
      "15 : [u'Students', u'', u'']\n",
      "16 : [u'']\n",
      "17 : [u'']\n",
      "18 : [u'', u'']\n",
      "19 : [u'RBS Job offers']\n",
      "20 : [u'Gossip: JL and her kids']\n",
      "21 : [u'']\n",
      "22 : [u'Professors']\n",
      "23 : [u'User Comments']\n",
      "24 : [u'']\n",
      "25 : [u'User comments']\n"
     ]
    }
   ],
   "source": [
    "group_2 = view_group(n_clusters_ , sample_doc, \"topic\", labels)\n",
    "x = 0\n",
    "for i in group_2:\n",
    "    print x,':',i\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : ['1.25000 yamaha']\n",
      "1 : ['1.00000 suzuki']\n",
      "2 : []\n",
      "3 : ['1.00000 rb']\n",
      "4 : ['1.00000 bank']\n",
      "5 : ['1.00000 runner', '1.00000 marathon', '1.00000 congratul', '1.00000 bank']\n",
      "6 : ['1.00000 jennif']\n",
      "7 : ['1.00000 sporti', '1.00000 max', '1.00000 lopez', '1.00000 jersey', '1.00000 jennif', '1.00000 emm']\n",
      "8 : ['1.33333 mazda', '0.66667 mazda3', '0.66667 ford']\n",
      "9 : ['1.00000 lopez', '1.00000 jennif']\n",
      "10 : ['1.33333 berkeley', '1.00000 day', '0.66667 peopl']\n"
     ]
    }
   ],
   "source": [
    "centroid_list, centroid_word_list, score_list = find_centroid_score(tf,group,feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_true(all_doc):\n",
    "    topic_labels = []\n",
    "    minor_class_labels = []\n",
    "    major_class_labels = []\n",
    "    topic_dense = []\n",
    "    for doc in all_doc:\n",
    "        topic_labels.append(doc['topic'])\n",
    "        minor_class_labels.append(doc['minor_class'])\n",
    "        major_class_labels.append(doc['major_class'])\n",
    "        topic_dense.append(doc['topic_dense'])\n",
    "    return topic_labels,minor_class_labels,major_class_labels,topic_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_labels,minor_class_labels,major_class_labels,topic_dense = get_labels_true(sample_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_cluster_score(labels_true, labels):\n",
    "    homogeneity, completeness, v_measure  = metrics.homogeneity_completeness_v_measure(labels_true, labels)\n",
    "    adjusted_rand_score =  metrics.adjusted_rand_score(labels_true, labels)\n",
    "    adjusted_mutual_info_score = metrics.adjusted_mutual_info_score(labels_true, labels)\n",
    "    fowlkes_mallows_score = metrics.fowlkes_mallows_score(labels_true, labels)\n",
    "    return homogeneity, completeness, v_measure, adjusted_rand_score, adjusted_mutual_info_score, fowlkes_mallows_score\n",
    "\n",
    "# Measured in three levels major_class > minor_class > topic\n",
    "\n",
    "# 1 : use all topic \n",
    "# 2 : use only topic happen > 3 time and not ignore topic in true label\n",
    "# 3 : use only topic that Selected by cluster algorithm \n",
    "# 4 : 2 U 3 \n",
    "def cluster_score(time,levels,description,labels_true, labels,topic_dense):\n",
    "    n = len(labels_true)\n",
    "    #1\n",
    "    homogeneity, completeness, v_measure, adjusted_rand_score, adjusted_mutual_info_score, fowlkes_mallows_score = cal_cluster_score(labels_true, labels)\n",
    "    \n",
    "    db[col_output].update_one({'time':time,'levels':levels,'description':des,'type':2},\n",
    "                              {\"$set\":{'homogeneity_score':homogeneity, \n",
    "                                       'completeness_score':completeness, \n",
    "                                       'v_measure_score':v_measure, \n",
    "                                       'adjusted_rand_score':adjusted_rand_score, \n",
    "                                       'adjusted_mutual_info_score':adjusted_mutual_info_score, \n",
    "                                       'fowlkes_mallows_score':fowlkes_mallows_score}}, upsert=True)\n",
    "    \n",
    "    #2\n",
    "    filter_labels_true = []\n",
    "    filter_labels = []\n",
    "    for i in range(n):\n",
    "        if topic_dense[i] == 1:\n",
    "            filter_labels_true.append(labels_true[i])\n",
    "            filter_labels.append(labels[i])\n",
    "    homogeneity, completeness, v_measure, adjusted_rand_score, adjusted_mutual_info_score, fowlkes_mallows_score = cal_cluster_score(filter_labels_true, filter_labels)\n",
    "    \n",
    "    db[col_output].update_one({'time':time,'levels':levels,'description':des,'type':2},\n",
    "                              {\"$set\":{'homogeneity_score':homogeneity, \n",
    "                                       'completeness_score':completeness, \n",
    "                                       'v_measure_score':v_measure, \n",
    "                                       'adjusted_rand_score':adjusted_rand_score, \n",
    "                                       'adjusted_mutual_info_score':adjusted_mutual_info_score, \n",
    "                                       'fowlkes_mallows_score':fowlkes_mallows_score}}, upsert=True)\n",
    "\n",
    "    #3\n",
    "    filter_labels_true = []\n",
    "    filter_labels = []\n",
    "    for i in range(n):\n",
    "        if labels[i] != -1:\n",
    "            filter_labels_true.append(labels_true[i])\n",
    "            filter_labels.append(labels[i])\n",
    "    cal_cluster_score(filter_labels_true, filter_labels)\n",
    "    db[col_output].update_one({'time':time,'levels':levels,'description':des,'type':3},\n",
    "                      {\"$set\":{'homogeneity_score':homogeneity, \n",
    "                               'completeness_score':completeness, \n",
    "                               'v_measure_score':v_measure, \n",
    "                               'adjusted_rand_score':adjusted_rand_score, \n",
    "                               'adjusted_mutual_info_score':adjusted_mutual_info_score, \n",
    "                               'fowlkes_mallows_score':fowlkes_mallows_score}}, upsert=True)\n",
    "\n",
    "    #4\n",
    "    filter_labels_true = []\n",
    "    filter_labels = []\n",
    "    for i in range(n):\n",
    "        if topic_dense[i] == 1 or labels[i] != -1:\n",
    "            filter_labels_true.append(labels_true[i])\n",
    "            filter_labels.append(labels[i])\n",
    "    cal_cluster_score(filter_labels_true, filter_labels)\n",
    "    db[col_output].update_one({'time':time,'levels':levels,'description':des,'type':4},\n",
    "                      {\"$set\":{'homogeneity_score':homogeneity, \n",
    "                               'completeness_score':completeness, \n",
    "                               'v_measure_score':v_measure, \n",
    "                               'adjusted_rand_score':adjusted_rand_score, \n",
    "                               'adjusted_mutual_info_score':adjusted_mutual_info_score, \n",
    "                               'fowlkes_mallows_score':fowlkes_mallows_score}}, upsert=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "print len(topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.616678911169 0.719784797462 0.664254633041\n"
     ]
    }
   ],
   "source": [
    "labels = [1,1,4,2,3,3]\n",
    "labels_true = [1,1,1,1,1,1]\n",
    "\n",
    "homogeneity, completeness, v_measure  = metrics.homogeneity_completeness_v_measure(labels_true, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 1.000\n",
      "Completeness: 0.000\n",
      "V-measure: 0.000\n",
      "Adjusted Rand Index: 0.000\n",
      "Adjusted Mutual Information: 0.000\n",
      "Fowlkes-Mallows scores: 0.365\n"
     ]
    }
   ],
   "source": [
    "# Homogeneity  :  each cluster contains only members of a single class.\n",
    "# Completeness :  all members of a given class are assigned to the same cluster.\n",
    "# V-measure    :  harmonic mean between homogeneity and completeness\n",
    "\n",
    "# ~ Accuracy\n",
    "# Adjusted Rand Index  :  (คู่ของข้อมูลที่อยู่ในกลุ่มเดียวกันทั้งในความจริงและที่หามาได้ + คู่ของข้อมูลที่อยู่ต่างกลุ่มกันทั้งในความจริงและที่หามาได้)/ จำนวนคู่ที่เป็นไได้ทั้งหมด\n",
    "# Adjusted Mutual Information  : เหมือนด้านบน แต่เปลี่ยนไปใ้ค่าความน่าจะเป็นแทนผลลัพธ์ \n",
    "# Fowlkes-Mallows scores  :  จำนวนจุดที่ถูก / ทั้งหมด\n",
    "\n",
    "labels = [1,1,4,2,3,3]\n",
    "labels_true = [1,1,1,1,1,1]\n",
    "\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "print(\"Fowlkes-Mallows scores: %0.3f\"\n",
    "      % metrics.fowlkes_mallows_score(labels_true, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Silhouette Coefficient  :  \\xe0\\xb9\\x84\\xe0\\xb8\\xa1\\xe0\\xb9\\x88\\xe0\\xb8\\xa3\\xe0\\xb8\\xb9\\xe0\\xb9\\x89 labels_true \\xe0\\xb9\\x80\\xe0\\xb8\\x97\\xe0\\xb8\\xb5\\xe0\\xb8\\xa2\\xe0\\xb8\\x9a sim \\xe0\\xb8\\xa3\\xe0\\xb8\\xb0\\xe0\\xb8\\xab\\xe0\\xb8\\xa7\\xe0\\xb9\\x88\\xe0\\xb8\\xb2\\xe0\\xb8\\x87\\xe0\\xb8\\x81\\xe0\\xb8\\xa5\\xe0\\xb8\\xb8\\xe0\\xb9\\x88\\xe0\\xb8\\xa1\\xe0\\xb8\\x97\\xe0\\xb8\\xb5\\xe0\\xb9\\x88\\xe0\\xb8\\x88\\xe0\\xb8\\xb1\\xe0\\xb8\\x9a\\xe0\\xb9\\x84\\xe0\\xb8\\x94\\xe0\\xb9\\x89 \\xe0\\xb8\\x81\\xe0\\xb8\\xb1\\xe0\\xb8\\x9a\\xe0\\xb8\\x81\\xe0\\xb8\\xa5\\xe0\\xb8\\xb8\\xe0\\xb9\\x88\\xe0\\xb8\\xa1\\xe0\\xb9\\x83\\xe0\\xb8\\x81\\xe0\\xb8\\xa5\\xe0\\xb9\\x89\\xe0\\xb9\\x80\\xe0\\xb8\\x84\\xe0\\xb8\\xb5\\xe0\\xb8\\xa2\\xe0\\xb8\\x87\\xe0\\xb9\\x80\\xe0\\xb8\\x9e\\xe0\\xb8\\xb7\\xe0\\xb9\\x88\\xe0\\xb8\\xad\\xe0\\xb8\\x94\\xe0\\xb8\\xb9\\xe0\\xb8\\xa7\\xe0\\xb9\\x88\\xe0\\xb8\\xb2\\xe0\\xb8\\x88\\xe0\\xb8\\xb1\\xe0\\xb8\\x9a\\xe0\\xb8\\x81\\xe0\\xb8\\xa5\\xe0\\xb8\\xb8\\xe0\\xb9\\x88\\xe0\\xb8\\xa1\\xe0\\xb8\\xad\\xe0\\xb8\\xad\\xe0\\xb8\\x81\\xe0\\xb8\\xa1\\xe0\\xb8\\xb2\\xe0\\xb9\\x84\\xe0\\xb8\\x94\\xe0\\xb9\\x89\\xe0\\xb8\\x94\\xe0\\xb8\\xb5\\xe0\\xb9\\x84\\xe0\\xb8\\xab\\xe0\\xb8\\xa1 '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"No labels_true\"\n",
    "\"Silhouette Coefficient  :  ไม่รู้ labels_true เทียบ sim ระหว่างกลุ่มที่จับได้ กับกลุ่มใกล้เคียงเพื่อดูว่าจับกลุ่มออกมาได้ดีไหม \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
